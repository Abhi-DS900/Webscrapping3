{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "# Headless mode\n",
    "options = Options()  # Initialize an instance of the Options class\n",
    "options.headless = True  # True -> Headless mode activated\n",
    "options.add_argument('window-size=1920x1080')  # Set a big window size, so all the data will be displayed\n",
    "\n",
    "\n",
    "# Open NFT web page\n",
    "web = \"https://raritysniper.com/nft-collections\"\n",
    "path = r'C:\\Users\\vempa\\OneDrive\\Desktop\\Abhi\\Intershala_DataScience\\Interview - Final\\web scrapping\\Udemy-course\\chromedriver'\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(web)\n",
    "driver.maximize_window()\n",
    "\n",
    "            \n",
    "# Define variables\n",
    "records = []\n",
    "sheet1 = []\n",
    "collection_list_final = []\n",
    "collection_list_Ndupli = []\n",
    "Detail_list_final = []\n",
    "Detail_list_Ndupli = []\n",
    "String_val = ''\n",
    "MP1_N = ' '\n",
    "MP1_URL = ' '\n",
    "MP2_URL = ' '\n",
    "MP3_URL = ' '\n",
    "MP4_URL = ' '\n",
    "MP5_URL = ' '\n",
    "MP6_URL = ' '\n",
    "MP7_URL = ' '\n",
    "MP8_URL = ' '\n",
    "MP9_URL = ' '\n",
    "\n",
    "\n",
    "# End scroll\n",
    "scrolling = True\n",
    "while scrolling:\n",
    "    time.sleep(10)\n",
    "    # collect all the collections\n",
    "    collection_list = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//div[@class=\"mx-auto p-2 min-h-full\"]//a[@href and not(contains(@href,\"twitter\")) and not(contains(@href,\"discord\"))]')))\n",
    "    collection_list_final = collection_list_final + collection_list\n",
    "    collection_list_Ndupli = set(collection_list_final) # to avoid duplicates while scrolling\n",
    "    \n",
    "    # Get the initial scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(10)\n",
    "        # Calculate new scroll height and compare it with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        # condition 1\n",
    "        if new_height == last_height:  # if the new and last height are equal, it means that there isn't any new page to load, so we stop scrolling\n",
    "            scrolling = False\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "#             pdb.set_trace()\n",
    "            break   \n",
    "\n",
    "#Iterate over collections\n",
    "for project in collection_list_Ndupli:\n",
    "    # URL and Collection name for sheet 1 data\n",
    "    String_val = project.get_attribute(\"alt\")\n",
    "    new_path = project.get_attribute(\"href\")\n",
    "    if not String_val:\n",
    "        String_val = new_path.split('/')[-1]\n",
    "    sheet1.append((String_val, new_path))\n",
    "    web = new_path\n",
    "    #chrome driver path\n",
    "    path = r'C:\\Users\\vempa\\OneDrive\\Desktop\\Abhi\\Intershala_DataScience\\Interview - Final\\web scrapping\\Udemy-course\\chromedriver'\n",
    "    driver = webdriver.Chrome(path, options=options)\n",
    "    driver.get(web)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    scrolling1 = True\n",
    "    while scrolling1:\n",
    "        time.sleep(10)\n",
    "        Detail_list = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, '//blockquote')))\n",
    "        Detail_list_final = Detail_list_final + Detail_list\n",
    "        Detail_list_Ndupli = set(Detail_list_final)\n",
    "            \n",
    "        # Get the initial scroll height\n",
    "        last_height1 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            # Wait to load page\n",
    "            time.sleep(10)\n",
    "            # Calculate new scroll height and compare it with last scroll height\n",
    "            new_height1 = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            # condition 1\n",
    "            if new_height1 == last_height1:  # if the new and last height are equal, it means that there isn't any new page to load, so we stop scrolling\n",
    "                scrolling1 = False\n",
    "                break\n",
    "            else:\n",
    "                last_height1 = new_height1\n",
    "#                 pdb.set_trace()\n",
    "                break\n",
    "#     pdb.set_trace()\n",
    "    # just clearing the variables after finishing their task to reload data again\n",
    "    MP1_URL=MP2_URL=MP3_URL=MP4_URL=MP5_URL=MP6_URL=MP7_URL=MP8_URL= MP9_URL= None\n",
    "    MP1_N=MP2_N=MP3_N=MP4_N=MP5_N=MP6_N=MP7_N=MP8_N=MP9_N=None\n",
    "#market place urls and names\n",
    "    try:    \n",
    "        MP1 = driver.find_element(By.XPATH,'.//a[contains(@rel, \"noopener\")][1]')\n",
    "        MP1_URL = MP1.get_attribute(\"href\")\n",
    "        MP1N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][1]//img')\n",
    "        MP1_N = MP1N.get_attribute(\"alt\")\n",
    "        if not MP1_N:\n",
    "            MP1_N = MP1_URL.split('/')[2].split('.')[0]\n",
    "        Cn = {}\n",
    "        Cn[MP1_N] = MP1_URL\n",
    "        MP2 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][2]')\n",
    "        MP2_URL = MP2.get_attribute(\"href\")\n",
    "        MP2N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][2]//img')\n",
    "        MP2_N = MP2N.get_attribute(\"alt\")\n",
    "        if not MP2_N:\n",
    "            MP2_N = MP2_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP2_N] = MP2_URL\n",
    "        MP3 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][3]')\n",
    "        MP3_URL = MP3.get_attribute(\"href\")\n",
    "        MP3N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][3]//img')\n",
    "        MP3_N = MP3N.get_attribute(\"alt\")\n",
    "        if not MP3_N:\n",
    "            MP3_N = MP3_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP3_N] = MP3_URL\n",
    "        MP4 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][4]')\n",
    "        MP4_URL = MP4.get_attribute(\"href\")\n",
    "        MP4N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][4]//img')\n",
    "        MP4_N = MP4N.get_attribute(\"alt\")\n",
    "        if not MP4_N:\n",
    "            MP4_N = MP4_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP4_N] = MP4_URL\n",
    "        MP5 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][5]')\n",
    "        MP5_URL = MP5.get_attribute(\"href\")\n",
    "        MP5N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][5]//img')\n",
    "        MP5_N = MP5N.get_attribute(\"alt\")\n",
    "        if not MP5_N:\n",
    "            MP5_N = MP5_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP5_N] = MP5_URL\n",
    "        MP6 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][6]')\n",
    "        MP6_URL = MP6.get_attribute(\"href\")\n",
    "        MP6N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][6]//img')\n",
    "        MP6_N = MP6N.get_attribute(\"alt\")\n",
    "        if not MP6_N:\n",
    "            MP6_N = MP6_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP6_N] = MP6_URL\n",
    "        MP7 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][7]')\n",
    "        MP7_URL = MP7.get_attribute(\"href\")\n",
    "        MP7N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][7]//img')\n",
    "        MP7_N = MP7N.get_attribute(\"alt\")\n",
    "        if not MP7_N:\n",
    "            MP7_N = MP7_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP7_N] = MP7_URL\n",
    "        MP8 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][8]')\n",
    "        MP8_URL = MP8.get_attribute(\"href\")\n",
    "        MP8N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][8]//img')\n",
    "        MP8_N = MP8N.get_attribute(\"alt\")\n",
    "        if not MP8_N:\n",
    "            MP8_N = MP8_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP8_N] = MP8_URL    \n",
    "        MP9 = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][9]')\n",
    "        MP9_URL = MP9.get_attribute(\"href\")\n",
    "        MP9N = driver.find_element(By.XPATH,'.//a[contains(@rel,\"noopener\")][9]//img')\n",
    "        MP9_N = MP9N.get_attribute(\"alt\")\n",
    "        if not MP9_N:\n",
    "            MP9_N = MP9_URL.split('/')[2].split('.')[0]\n",
    "        Cn[MP9_N] = MP9_URL\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    a = 0\n",
    "    b = 1\n",
    "    for detail in Detail_list_Ndupli:\n",
    "        a = a+1\n",
    "        # to avoid too many clicks on the website in short span of time  - after 20 times give some break time\n",
    "        if a == b*20:\n",
    "            time.sleep(10)\n",
    "            b=b+1\n",
    "        Rank = WebDriverWait(detail, 10).until(EC.presence_of_element_located((By.XPATH, './/div[contains(@class, \"text-primary\")]')))\n",
    "        Rank_text = Rank.text\n",
    "        ID = detail.find_element(By.XPATH,'.//div[contains(@class, \"text-blueGray-dark\")]').text\n",
    "        No = ID.split('#')\n",
    "\n",
    "        # open the new page by using the ID and get the score\n",
    "        try:\n",
    "            web = f'{new_path}/{str(No[1])}'\n",
    "        except:\n",
    "            print(No)\n",
    "        path = r'C:\\Users\\vempa\\OneDrive\\Desktop\\Abhi\\Intershala_DataScience\\Interview - Final\\web scrapping\\Udemy-course\\chromedriver'\n",
    "        driver = webdriver.Chrome(path, options=options)\n",
    "        driver.get(web)\n",
    "\n",
    "        Score = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, './/div[@class=\"truncate\"]//span[3]')))\n",
    "        Score_text = Score.text\n",
    "        driver.implicitly_wait(10)\n",
    "        # Append all the data of sheet 2 here\n",
    "        records.append((Rank_text, ID, Score_text,d['opensea'],d['looksrare'],d['x2y2'],d['rarible'],d['genie'],d['gem'],d['imaginaryones'],d['twitter'],d['instagram']))\n",
    "\n",
    "\n",
    "# Convert to data frames with column names            \n",
    "df_nft_col = pd.DataFrame(records, columns=['Rank','ID', 'Score','opensea','looksrare','x2y2','rarible','genie','gem','imaginaryones','twitter','instagram'])\n",
    "df_url = pd.DataFrame(sheet1, columns=['Collection Name','URL' ])  \n",
    "\n",
    "# Write to excel file\n",
    "writer = pd.ExcelWriter('NFT_File.xlsx', engine='xlsxwriter')\n",
    "\n",
    "#store your dataframes in a  dict, where the key is the sheet name you want\n",
    "frames = {'NFT URL': df_url, 'details': df_nft_col}\n",
    "\n",
    "#now loop thru and put each on a specific sheet\n",
    "for sheet, frame in  frames.items(): # .use .items for python 3.X\n",
    "    frame.to_excel(writer, sheet_name = sheet)\n",
    "\n",
    "#critical last step\n",
    "writer.save()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b16f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cd1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
